# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the PyFlink package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PyFlink 2.3.dev0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-11 10:53+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh\n"
"Language-Team: zh <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.18.0\n"

#: ../../user_guide/table/udfs.rst:21
msgid "Python User-defined Functions"
msgstr "Python 自定义函数"

#: ../../user_guide/table/udfs.rst:23
msgid ""
"User-defined functions are important features, because they significantly"
" extend the expressiveness of Python Table API programs."
msgstr "用户自定义函数是重要的功能，因为它们极大地扩展了 Python Table API 程序的表达能力。"

#: ../../user_guide/table/udfs.rst:25
msgid ""
"**NOTE:** Python UDF execution requires Python version (3.9, 3.10, 3.11 "
"or 3.12) with PyFlink installed. It's required on both the client side "
"and the cluster side."
msgstr ""
"**注意:** 要执行 Python 用户自定义函数，客户端和集群端都需要安装 Python 3.9 以上版本"
"（3.9、3.10、3.11 或 3.12），并安装 PyFlink。"

#: ../../user_guide/table/udfs.rst:28
msgid "Scalar Functions"
msgstr "标量函数（ScalarFunction）"

#: ../../user_guide/table/udfs.rst:30
msgid ""
"It supports to use Python scalar functions in Python Table API programs. "
"In order to define a Python scalar function, one can extend the base "
"class ``ScalarFunction`` in ``pyflink.table.udf`` and implement an "
"evaluation method. The behavior of a Python scalar function is defined by"
" the evaluation method which is named ``eval``. The evaluation method can"
" support variable arguments, such as ``eval(*args)``."
msgstr ""
"PyFlink 支持在 Python Table API 程序中使用 Python 标量函数。 如果要定义 Python 标量函数，"
"可以继承 ``pyflink.table.udf`` 中的基类 ``ScalarFunction``，并实现 ``eval`` 方法。"
"Python 标量函数的行为由名为 ``eval`` 的方法定义，``eval`` 方法支持可变长参数，"
"例如 ``eval(*args)``。"

#: ../../user_guide/table/udfs.rst:35
msgid ""
"The following example shows how to define your own Python hash code "
"function, register it in the TableEnvironment, and call it in a query. "
"Note that you can configure your scalar function via a constructor before"
" it is registered:"
msgstr ""
"以下示例显示了如何定义自己的 Python 哈希函数、如何在 TableEnvironment 中注册它"
"以及如何在作业中使用它。"

#: ../../user_guide/table/udfs.rst:63
msgid ""
"It also supports to use Java/Scala scalar functions in Python Table API "
"programs."
msgstr "除此之外，还支持在Python Table API程序中使用 Java / Scala 标量函数。"

#: ../../user_guide/table/udfs.rst:94
msgid ""
"There are many ways to define a Python scalar function besides extending "
"the base class ``ScalarFunction``. The following examples show the "
"different ways to define a Python scalar function which takes two columns"
" of bigint as the input parameters and returns the sum of them as the "
"result."
msgstr ""
"除了扩展基类 ``ScalarFunction`` 之外，还支持多种方式来定义 Python 标量函数。"
"以下示例显示了多种定义 Python 标量函数的方式。该函数需要两个类型为 bigint 的参数"
"作为输入参数，并返回它们的总和作为结果。"

#: ../../user_guide/table/udfs.rst:137
msgid "Table Functions"
msgstr "表值函数（TableFunction）"

#: ../../user_guide/table/udfs.rst:139
msgid ""
"Similar to a Python user-defined scalar function, a user-defined table "
"function takes zero, one, or multiple scalar values as input parameters. "
"However in contrast to a scalar function, it can return an arbitrary "
"number of rows as output instead of a single value. The return type of a "
"Python UDTF could be of types Iterable, Iterator or generator."
msgstr ""
"与 Python 用户自定义标量函数类似，Python 用户自定义表值函数以零个，一个或者多个列"
"作为输入参数。但是，与标量函数不同的是，表值函数可以返回任意数量的行作为输出"
"而不是单个值。Python 用户自定义表值函数的返回类型可以是 Iterable，Iterator "
"或 generator 类型。"

#: ../../user_guide/table/udfs.rst:144
msgid ""
"The following example shows how to define your own Python multi emit "
"function, register it in the TableEnvironment, and call it in a query."
msgstr ""
"以下示例说明了如何定义自己的 Python 自定义表值函数，将其注册到 TableEnvironment "
"中，并在作业中使用它。"

#: ../../user_guide/table/udfs.rst:174
msgid ""
"It also supports to use Java/Scala table functions in Python Table API "
"programs."
msgstr "除此之外，还支持在 Python Table API 程序中使用 Java / Scala 表值函数。"

#: ../../user_guide/table/udfs.rst:216
msgid ""
"Like Python scalar functions, you can use the above five ways to define "
"Python TableFunctions."
msgstr "像 Python 标量函数一样，您可以使用上述五种方式来定义 Python 表值函数。"

#: ../../user_guide/table/udfs.rst:219
msgid ""
"The only difference is that the return type of Python Table Functions "
"needs to be an iterable, iterator or generator."
msgstr ""
"唯一的区别是，Python 表值函数的返回类型必须是 iterable（可迭代子类）, "
"iterator（迭代器） or generator（生成器）。"

#: ../../user_guide/table/udfs.rst:241
msgid "Aggregate Functions"
msgstr "聚合函数（AggregateFunction）"

#: ../../user_guide/table/udfs.rst:243
msgid ""
"A user-defined aggregate function (*UDAGG*) maps scalar values of "
"multiple rows to a new scalar value."
msgstr ""

#: ../../user_guide/table/udfs.rst:245
msgid ""
"**NOTE:** Currently the general user-defined aggregate function is only "
"supported in the GroupBy aggregation and Group Window Aggregation in "
"streaming mode. For batch mode, it's currently not supported and it is "
"recommended to use the `Vectorized Aggregate Functions`_."
msgstr ""

#: ../../user_guide/table/udfs.rst:247
msgid ""
"The behavior of an aggregate function is centered around the concept of "
"an accumulator. The *accumulator* is an intermediate data structure that "
"stores the aggregated values until a final aggregation result is "
"computed."
msgstr ""

#: ../../user_guide/table/udfs.rst:251
msgid ""
"For each set of rows that need to be aggregated, the runtime will create "
"an empty accumulator by calling ``create_accumulator()``. Subsequently, "
"the ``accumulate(...)`` method of the aggregate function will be called "
"for each input row to update the accumulator. Currently after each row "
"has been processed, the ``get_value(...)`` method of the aggregate "
"function will be called to compute the aggregated result."
msgstr ""

#: ../../user_guide/table/udfs.rst:256 ../../user_guide/table/udfs.rst:420
msgid ""
"The following example shows how to define your own aggregate function and"
" call it in a query."
msgstr ""

#: ../../user_guide/table/udfs.rst:335
msgid ""
"The ``accumulate(...)`` method of our ``WeightedAvg`` class takes three "
"input arguments. The first one is the accumulator and the other two are "
"user-defined inputs. In order to calculate a weighted average value, the "
"accumulator needs to store the weighted sum and count of all the data "
"that have already been accumulated. In our example, we use a ``Row`` "
"object as the accumulator. Accumulators will be managed by Flink's "
"checkpointing mechanism and are restored in case of failover to ensure "
"exactly-once semantics."
msgstr ""

#: ../../user_guide/table/udfs.rst:342 ../../user_guide/table/udfs.rst:482
msgid "Mandatory and Optional Methods"
msgstr ""

#: ../../user_guide/table/udfs.rst:344
msgid ""
"**The following methods are mandatory for each** ``AggregateFunction`` "
"**:**"
msgstr ""

#: ../../user_guide/table/udfs.rst:346 ../../user_guide/table/udfs.rst:486
msgid "``create_accumulator()``"
msgstr ""

#: ../../user_guide/table/udfs.rst:347 ../../user_guide/table/udfs.rst:487
msgid "``accumulate(...)``"
msgstr ""

#: ../../user_guide/table/udfs.rst:348
msgid "``get_value(...)``"
msgstr ""

#: ../../user_guide/table/udfs.rst:350
msgid ""
"**The following methods of** ``AggregateFunction`` **are required "
"depending on the use case:**"
msgstr ""

#: ../../user_guide/table/udfs.rst:352
msgid ""
"``retract(...)`` is required when there are operations that could "
"generate retraction messages before the current aggregation operation, "
"e.g. group aggregate, outer join. This method is optional, but it is "
"strongly recommended to be implemented to ensure the UDAF can be used in "
"any use case."
msgstr ""

#: ../../user_guide/table/udfs.rst:353
msgid "``merge(...)`` is required for session window and hop window aggregations."
msgstr ""

#: ../../user_guide/table/udfs.rst:354
msgid ""
"``get_result_type()`` and ``get_accumulator_type()`` is required if the "
"result type and accumulator type would not be specified in the ``udaf`` "
"decorator."
msgstr ""

#: ../../user_guide/table/udfs.rst:357 ../../user_guide/table/udfs.rst:496
msgid "ListView and MapView"
msgstr ""

#: ../../user_guide/table/udfs.rst:359
msgid ""
"If an accumulator needs to store large amounts of data, "
"``pyflink.table.ListView`` and ``pyflink.table.MapView`` could be used "
"instead of list and dict. These two data structures provide the similar "
"functionalities as list and dict, however usually having better "
"performance by leveraging Flink's state backend to eliminate unnecessary "
"state access. You can use them by declaring ``DataTypes.LIST_VIEW(...)`` "
"and ``DataTypes.MAP_VIEW(...)`` in the accumulator type, e.g.:"
msgstr ""

#: ../../user_guide/table/udfs.rst:391
msgid "Currently there are 2 limitations to use the ListView and MapView:"
msgstr ""

#: ../../user_guide/table/udfs.rst:393
msgid "The accumulator must be a ``Row``."
msgstr ""

#: ../../user_guide/table/udfs.rst:394
msgid ""
"The ``ListView`` and ``MapView`` must be the first level children of the "
"``Row`` accumulator."
msgstr ""

#: ../../user_guide/table/udfs.rst:396
msgid ""
"Please refer to the `documentation of the corresponding classes "
"<https://nightlies.apache.org/flink/flink-docs-"
"stable/api/python/pyflink.table.html#pyflink.table.ListView>`_ for more "
"information about this advanced feature."
msgstr ""

#: ../../user_guide/table/udfs.rst:398
msgid ""
"**NOTE:** For reducing the data transmission cost between Python UDF "
"worker and Java process caused by accessing the data in Flink states "
"(e.g. accumulators and data views), there is a cached layer between the "
"raw state handler and the Python state backend. You can adjust the values"
" of these configuration options to change the behavior of the cache layer"
" for best performance: ``python.state.cache-size``, ``python.map-state"
".read-cache-size``, ``python.map-state.write-cache-size``, ``python.map-"
"state.iterate-response-batch-size``. For more details please refer to "
":doc:`../configuration`."
msgstr ""
"**注意:** 为了减少由于访问 Flink 状态（如累加器和数据视图）中的数据而导致的 Python "
"UDF worker 和 Java 进程之间的数据传输开销，在原始状态处理器和 Python 状态后端之间"
"有一个缓存层。您可以调整以下配置选项的值来更改缓存层的行为以获得最佳性能: "
"``python.state.cache-size``、``python.map-state.read-cache-size``、"
"``python.map-state.write-cache-size``、"
"``python.map-state.iterate-response-batch-size``。"
"更多详细信息请参阅 :doc:`../configuration`。"

#: ../../user_guide/table/udfs.rst:404
msgid "Table Aggregate Functions"
msgstr "Table Aggregate Functions"

#: ../../user_guide/table/udfs.rst:406
msgid ""
"A user-defined table aggregate function (*UDTAGG*) maps scalar values of "
"multiple rows to zero, one, or multiple rows (or structured types). The "
"returned record may consist of one or more fields. If an output record "
"consists of only a single field, the structured record can be omitted, "
"and a scalar value can be emitted that will be implicitly wrapped into a "
"row by the runtime."
msgstr ""

#: ../../user_guide/table/udfs.rst:410
msgid ""
"**NOTE:** Currently the general user-defined table aggregate function is "
"only supported in the GroupBy aggregation in streaming mode."
msgstr ""

#: ../../user_guide/table/udfs.rst:412
msgid ""
"Similar to an `Aggregate Functions`_, the behavior of a table aggregate "
"is centered around the concept of an accumulator. The accumulator is an "
"intermediate data structure that stores the aggregated values until a "
"final aggregation result is computed."
msgstr ""

#: ../../user_guide/table/udfs.rst:415
msgid ""
"For each set of rows that needs to be aggregated, the runtime will create"
" an empty accumulator by calling ``create_accumulator()``. Subsequently, "
"the ``accumulate(...)`` method of the function is called for each input "
"row to update the accumulator. Once all rows have been processed, the "
"``emit_value(...)`` method of the function is called to compute and "
"return the final result."
msgstr ""

#: ../../user_guide/table/udfs.rst:475
msgid ""
"The ``accumulate(...)`` method of our ``Top2`` class takes two inputs. "
"The first one is the accumulator and the second one is the user-defined "
"input. In order to calculate a result, the accumulator needs to store the"
" 2 highest values of all the data that has been accumulated. Accumulators"
" are automatically managed by Flink's checkpointing mechanism and are "
"restored in case of a failure to ensure exactly-once semantics. The "
"result values are emitted together with a ranking index."
msgstr ""

#: ../../user_guide/table/udfs.rst:484
msgid ""
"**The following methods are mandatory for each** "
"``TableAggregateFunction`` **:**"
msgstr ""

#: ../../user_guide/table/udfs.rst:488
msgid "``emit_value(...)``"
msgstr ""

#: ../../user_guide/table/udfs.rst:490
msgid ""
"**The following methods of** ``TableAggregateFunction`` **are required "
"depending on the use case:**"
msgstr ""

#: ../../user_guide/table/udfs.rst:492
msgid ""
"``retract(...)`` is required when there are operations that could "
"generate retraction messages before the current aggregation operation, "
"e.g. group aggregate, outer join. This method is optional, but it is "
"strongly recommended to be implemented to ensure the UDTAF can be used in"
" any use case."
msgstr ""

#: ../../user_guide/table/udfs.rst:493
msgid ""
"``get_result_type()`` and ``get_accumulator_type()`` is required if the "
"result type and accumulator type would not be specified in the ``udtaf`` "
"decorator."
msgstr ""

#: ../../user_guide/table/udfs.rst:498
msgid ""
"Similar to `Aggregate Functions`_, we can also use ListView and MapView "
"in Table Aggregate Function."
msgstr ""

#: ../../user_guide/table/udfs.rst:530
msgid "Vectorized User-defined Functions"
msgstr "向量化自定义函数"

#: ../../user_guide/table/udfs.rst:532
msgid ""
"Vectorized Python user-defined functions are functions which are executed"
" by transferring a batch of elements between JVM and Python VM in Arrow "
"columnar format. The performance of vectorized Python user-defined "
"functions are usually much higher than non-vectorized Python user-defined"
" functions as the serialization/deserialization overhead and invocation "
"overhead are much reduced. Besides, users could leverage the popular "
"Python libraries such as Pandas, Numpy, etc for the vectorized Python "
"user-defined functions implementation. These Python libraries are highly "
"optimized and provide high-performance data structures and functions. It "
"shares the similar way as the non-vectorized user-defined functions on "
"how to define vectorized user-defined functions. Users only need to add "
"an extra parameter ``func_type=\"pandas\"`` in the decorator ``udf`` or "
"``udaf`` to mark it as a vectorized user-defined function."
msgstr ""
"向量化 Python 用户自定义函数，是在执行时，通过在 JVM 和 Python VM 之间以 Arrow "
"列存格式批量传输数据，来执行的函数。向量化 Python 用户自定义函数的性能通常比"
"非向量化 Python 用户自定义函数要高得多，因为向量化 Python 用户自定义函数可以大大"
"减少序列化/反序列化的开销和调用开销。此外，用户可以利用流行的 Python 库（例如 "
"Pandas，Numpy 等）来实现向量化 Python 用户自定义函数的逻辑。这些 Python 库通常"
"经过高度优化，并提供了高性能的数据结构和功能。向量化用户自定义函数的定义，"
"与非向量化用户自定义函数具有相似的方式，用户只需要在调用 ``udf`` 或者 ``udaf`` "
"装饰器时添加一个额外的参数 ``func_type=\"pandas\"``，将其标记为一个向量化用户"
"自定义函数即可。"

#: ../../user_guide/table/udfs.rst:540
msgid "Vectorized Scalar Functions"
msgstr "向量化标量函数"

#: ../../user_guide/table/udfs.rst:542
msgid ""
"Vectorized Python scalar functions take ``pandas.Series`` as the inputs "
"and return a ``pandas.Series`` of the same length as the output. "
"Internally, Flink will split the input elements into batches, convert a "
"batch of input elements into ``Pandas.Series`` and then call user-defined"
" vectorized Python scalar functions for each batch of input elements. "
"Please refer to the config option ``python.fn-"
"execution.arrow.batch.size`` (see :doc:`../configuration`) for more "
"details on how to configure the batch size."
msgstr ""
"向量化 Python 标量函数以 ``pandas.Series`` 类型的参数作为输入，并返回与输入长度"
"相同的 ``pandas.Series``。在内部实现中，Flink 会将输入数据拆分为多个批次，"
"并将每一批次的输入数据转换为 ``Pandas.Series`` 类型，然后为每一批输入数据调用"
"用户自定义的向量化 Python 标量函数。请参阅配置选项 "
"``python.fn-execution.arrow.batch.size`` （见 :doc:`../configuration` ）"
"以获取有关如何配置批次大小的更多详细信息。"

#: ../../user_guide/table/udfs.rst:548
msgid ""
"Vectorized Python scalar function could be used in any places where non-"
"vectorized Python scalar functions could be used."
msgstr "向量化 Python 标量函数可以在任何可以使用非向量化 Python 标量函数的地方使用。"

#: ../../user_guide/table/udfs.rst:550
msgid ""
"The following example shows how to define your own vectorized Python "
"scalar function which computes the sum of two columns, and use it in a "
"query:"
msgstr ""
"以下示例显示了如何定义自己的向量化 Python 标量函数，该函数计算两列的总和，"
"并在查询中使用它："

#: ../../user_guide/table/udfs.rst:574
msgid "Vectorized Aggregate Functions"
msgstr "向量化聚合函数"

#: ../../user_guide/table/udfs.rst:576
msgid ""
"Vectorized Python aggregate functions takes one or more ``pandas.Series``"
" as the inputs and return one scalar value as output."
msgstr ""
"向量化 Python 聚合函数以一个或多个 ``pandas.Series`` 类型的参数作为输入，"
"并返回一个标量值作为输出。"

#: ../../user_guide/table/udfs.rst:579
msgid ""
"The return type does not support ``RowType`` and ``MapType`` for the time"
" being."
msgstr "现在返回类型还不支持 ``RowType`` 和 ``MapType``。"

#: ../../user_guide/table/udfs.rst:581
msgid ""
"Vectorized Python aggregate function could be used in ``GroupBy "
"Aggregation`` (Batch), ``GroupBy Window Aggregation`` (Batch and Stream) "
"and ``Over Window Aggregation`` (Batch and Stream bounded over window). "
"For more details on the usage of Aggregations, you can refer to the "
":flinkdoc:`relevant documentation "
"<docs/dev/table/tableapi/?code_tab=python#aggregations>`."
msgstr ""
"向量化 Python 聚合函数能够用在 ``GroupBy Aggregation`` （Batch），"
"``GroupBy Window Aggregation`` (Batch and Stream) 和 "
"``Over Window Aggregation`` (Batch and Stream bounded over window)。"
"关于聚合的更多使用细节，你可以参考 :flinkdoc:`相关文档 "
"<docs/dev/table/tableapi/?code_tab=python#aggregations>`。"

#: ../../user_guide/table/udfs.rst:586
msgid ""
"Pandas UDAF does not support partial aggregation. Besides, all the data "
"for a group or window will be loaded into memory at the same time during "
"execution and so you must make sure that the data of a group or window "
"could fit into the memory."
msgstr ""
"向量化聚合函数不支持部分聚合，而且一个组或者窗口内的所有数据，在执行的过程中，"
"会被同时加载到内存，所以需要确保所配置的内存大小足够容纳这些数据。"

#: ../../user_guide/table/udfs.rst:588
msgid ""
"The following example shows how to define your own vectorized Python "
"aggregate function which computes mean, and use it in ``GroupBy "
"Aggregation``, ``GroupBy Window Aggregation`` and ``Over Window "
"Aggregation``:"
msgstr ""
"以下示例显示了如何定一个自己的向量化聚合函数，该函数计算一列的平均值，并在 "
"``GroupBy Aggregation``, ``GroupBy Window Aggregation`` and "
"``Over Window Aggregation`` 使用它:"

#: ../../user_guide/table/udfs.rst:629
msgid ""
"There are many ways to define a vectorized Python aggregate functions. "
"The following examples show the different ways to define a vectorized "
"Python aggregate function which takes two columns of bigint as the inputs"
" and returns the sum of the maximum of them as the result."
msgstr ""
"除了直接定义一个 Python 函数之外，还支持多种方式来定义向量化 Python 聚合函数。"
"以下示例显示了多种定义向量化 Python 聚合函数的方式。该函数需要两个类型为 bigint "
"的参数作为输入参数，并返回它们的最大值的和作为结果。"

#: ../../user_guide/table/udfs.rst:684
msgid "Bundling UDFs"
msgstr "打包 UDFs"

#: ../../user_guide/table/udfs.rst:686
msgid ""
"To run Python UDFs (as well as Pandas UDFs) in any non-local mode, it is "
"strongly recommended bundling your Python UDF definitions using the "
"config option ``python-files`` (see :doc:`../configuration`), if your "
"Python UDFs live outside the file where the ``main()`` function is "
"defined. Otherwise, you may run into ``ModuleNotFoundError: No module "
"named 'my_udf'`` if you define Python UDFs in a file called "
"``my_udf.py``."
msgstr ""
"如果你在非 local 模式下运行 Python UDFs 和 Pandas UDFs，且 Python UDFs 没有定义"
"在含 ``main()`` 入口的 Python 主文件中，强烈建议你通过 ``python-files`` "
"（见 :doc:`../configuration` ）配置项指定 Python UDF 的定义。否则，如果你将 "
"Python UDFs 定义在名为 ``my_udf.py`` 的文件中，你可能会遇到 "
"``ModuleNotFoundError: No module named 'my_udf'`` 这样的报错。"

#: ../../user_guide/table/udfs.rst:693
msgid "Loading resources in UDFs"
msgstr "在 UDF 中载入资源"

#: ../../user_guide/table/udfs.rst:695
msgid ""
"There are scenarios when you want to load some resources in UDFs first, "
"then running computation (i.e., ``eval``) over and over again, without "
"having to re-load the resources. For example, you may want to load a "
"large deep learning model only once, then run batch prediction against "
"the model multiple times."
msgstr ""
"有时候，我们想在 UDF 中只载入一次资源，然后反复使用该资源进行计算。例如，你想在 "
"UDF 中首先载入一个巨大的深度学习模型，然后使用该模型多次进行预测。"

#: ../../user_guide/table/udfs.rst:700
msgid ""
"Overriding the ``open`` method of ``UserDefinedFunction`` is exactly what"
" you need."
msgstr "你要做的是重载 ``UserDefinedFunction`` 类的 ``open`` 方法。"

#: ../../user_guide/table/udfs.rst:717
msgid "Accessing job parameters"
msgstr "访问作业参数"

#: ../../user_guide/table/udfs.rst:719
msgid ""
"The ``open()`` method provides a ``FunctionContext`` that contains "
"information about the context in which user-defined functions are "
"executed, such as the metric group, the global job parameters, etc."
msgstr ""

#: ../../user_guide/table/udfs.rst:722
msgid ""
"The following information can be obtained by calling the corresponding "
"methods of ``FunctionContext``:"
msgstr ""

#: ../../user_guide/table/udfs.rst:727
msgid "Method"
msgstr ""

#: ../../user_guide/table/udfs.rst:728
msgid "Description"
msgstr ""

#: ../../user_guide/table/udfs.rst:729
msgid "``get_metric_group()``"
msgstr ""

#: ../../user_guide/table/udfs.rst:730
msgid "Metric group for this parallel subtask."
msgstr ""

#: ../../user_guide/table/udfs.rst:731
msgid "``get_job_parameter(name, default_value)``"
msgstr ""

#: ../../user_guide/table/udfs.rst:732
msgid "Global job parameter value associated with given key."
msgstr ""

#: ../../user_guide/table/udfs.rst:753
msgid "Testing User-Defined Functions"
msgstr "测试自定义函数"

#: ../../user_guide/table/udfs.rst:755
msgid "Suppose you have defined a Python user-defined function as following:"
msgstr "假如你定义了如下 Python 自定义函数："

#: ../../user_guide/table/udfs.rst:761
msgid ""
"To unit test it, you need to extract the original Python function using "
"``._func`` and then unit test it:"
msgstr ""
"如果要对它进行单元测试，首先需要通过 ``._func`` 从 UDF 对象中抽取原来的 Python "
"函数，然后才能测试："
