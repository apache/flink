/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.flink.streaming.runtime.tasks;

import org.apache.flink.annotation.Internal;
import org.apache.flink.annotation.VisibleForTesting;
import org.apache.flink.api.common.typeutils.TypeSerializer;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.runtime.event.AbstractEvent;
import org.apache.flink.runtime.execution.Environment;
import org.apache.flink.runtime.io.network.api.writer.RecordWriter;
import org.apache.flink.runtime.io.network.api.writer.RecordWriterDelegate;
import org.apache.flink.runtime.io.network.partition.consumer.IndexedInputGate;
import org.apache.flink.runtime.jobgraph.OperatorID;
import org.apache.flink.runtime.metrics.MetricNames;
import org.apache.flink.runtime.metrics.groups.OperatorMetricGroup;
import org.apache.flink.runtime.operators.coordination.OperatorEvent;
import org.apache.flink.runtime.operators.coordination.OperatorEventDispatcher;
import org.apache.flink.runtime.plugable.SerializationDelegate;
import org.apache.flink.streaming.api.graph.StreamConfig;
import org.apache.flink.streaming.api.graph.StreamConfig.InputConfig;
import org.apache.flink.streaming.api.graph.StreamConfig.SourceInputConfig;
import org.apache.flink.streaming.api.graph.StreamEdge;
import org.apache.flink.streaming.api.operators.Input;
import org.apache.flink.streaming.api.operators.MultipleInputStreamOperator;
import org.apache.flink.streaming.api.operators.OneInputStreamOperator;
import org.apache.flink.streaming.api.operators.Output;
import org.apache.flink.streaming.api.operators.SourceOperator;
import org.apache.flink.streaming.api.operators.StreamOperator;
import org.apache.flink.streaming.api.operators.StreamOperatorFactory;
import org.apache.flink.streaming.api.operators.StreamOperatorFactoryUtil;
import org.apache.flink.streaming.api.operators.StreamTaskStateInitializer;
import org.apache.flink.streaming.runtime.io.RecordWriterOutput;
import org.apache.flink.streaming.runtime.io.StreamTaskSourceInput;
import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
import org.apache.flink.streaming.runtime.streamstatus.StreamStatus;
import org.apache.flink.streaming.runtime.streamstatus.StreamStatusMaintainer;
import org.apache.flink.streaming.runtime.tasks.mailbox.MailboxExecutorFactory;
import org.apache.flink.util.FlinkException;
import org.apache.flink.util.OutputTag;
import org.apache.flink.util.SerializedValue;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.annotation.Nullable;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.stream.Collectors;

import static org.apache.flink.util.Preconditions.checkArgument;
import static org.apache.flink.util.Preconditions.checkNotNull;
import static org.apache.flink.util.Preconditions.checkState;

/**
 * The {@code OperatorChain} contains all operators that are executed as one chain within a single
 * {@link StreamTask}.
 *
 * <p>The main entry point to the chain is it's {@code mainOperator}. {@code mainOperator} is driving
 * the execution of the {@link StreamTask}, by pulling the records from network inputs and/or source
 * inputs and pushing produced records to the remaining chained operators.
 *
 * @param <OUT> The type of elements accepted by the chain, i.e., the input type of the chain's
 *              main operator.
 */
@Internal
public class OperatorChain<OUT, OP extends StreamOperator<OUT>> implements StreamStatusMaintainer {

	private static final Logger LOG = LoggerFactory.getLogger(OperatorChain.class);

	private final RecordWriterOutput<?>[] streamOutputs;

	private final WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput;

	/**
	 * For iteration, {@link StreamIterationHead} and {@link StreamIterationTail} used for executing
	 * feedback edges do not contain any operators, in which case, {@code mainOperatorWrapper} and
	 * {@code tailOperatorWrapper} are null.
	 *
	 * <p>Usually first operator in the chain is the same as {@link #mainOperatorWrapper}, but that's
	 * not the case if there are chained source inputs. In this case, one of the source inputs
	 * will be the first operator. For example the following operator chain is possible:
	 * first
	 *      \
	 *      main (multi-input) -> ... -> tail
	 *      /
	 * second
	 * Where "first" and "second" (there can be more) are chained source operators. When it comes to
	 * things like closing, stat initialisation or state snapshotting, the operator chain is traversed:
	 * first, second, main, ..., tail
	 * or in reversed order:
	 * tail, ..., main, second, first
	 */
	@Nullable private final StreamOperatorWrapper<OUT, OP> mainOperatorWrapper;
	@Nullable private final StreamOperatorWrapper<?, ?> firstOperatorWrapper;
	@Nullable private final StreamOperatorWrapper<?, ?> tailOperatorWrapper;

	private final Map<SourceInputConfig, ChainedSource> chainedSources;

	private final int numOperators;

	private final OperatorEventDispatcherImpl operatorEventDispatcher;

	/**
	 * Current status of the input stream of the operator chain.
	 * Watermarks explicitly generated by operators in the chain (i.e. timestamp
	 * assigner / watermark extractors), will be blocked and not forwarded if
	 * this value is {@link StreamStatus#IDLE}.
	 */
	private StreamStatus streamStatus = StreamStatus.ACTIVE;

	public OperatorChain(
			StreamTask<OUT, OP> containingTask,
			RecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate) {

		this.operatorEventDispatcher = new OperatorEventDispatcherImpl(
				containingTask.getEnvironment().getUserCodeClassLoader().asClassLoader(),
				containingTask.getEnvironment().getOperatorCoordinatorEventGateway());

		final ClassLoader userCodeClassloader = containingTask.getUserCodeClassLoader();
		final StreamConfig configuration = containingTask.getConfiguration();

		StreamOperatorFactory<OUT> operatorFactory = configuration.getStreamOperatorFactory(userCodeClassloader);

		// we read the chained configs, and the order of record writer registrations by output name
		Map<Integer, StreamConfig> chainedConfigs = configuration.getTransitiveChainedTaskConfigsWithSelf(userCodeClassloader);

		// create the final output stream writers
		// we iterate through all the out edges from this job vertex and create a stream output
		List<StreamEdge> outEdgesInOrder = configuration.getOutEdgesInOrder(userCodeClassloader);
		Map<StreamEdge, RecordWriterOutput<?>> streamOutputMap = new HashMap<>(outEdgesInOrder.size());
		this.streamOutputs = new RecordWriterOutput<?>[outEdgesInOrder.size()];

		// from here on, we need to make sure that the output writers are shut down again on failure
		boolean success = false;
		try {
			createChainOutputs(outEdgesInOrder, recordWriterDelegate, chainedConfigs, containingTask, streamOutputMap);

			// we create the chain of operators and grab the collector that leads into the chain
			List<StreamOperatorWrapper<?, ?>> allOpWrappers = new ArrayList<>(chainedConfigs.size());
			this.mainOperatorOutput = createOutputCollector(
				containingTask,
				configuration,
				chainedConfigs,
				userCodeClassloader,
				streamOutputMap,
				allOpWrappers,
				containingTask.getMailboxExecutorFactory());

			if (operatorFactory != null) {
				Tuple2<OP, Optional<ProcessingTimeService>> mainOperatorAndTimeService = StreamOperatorFactoryUtil.createOperator(
						operatorFactory,
						containingTask,
						configuration,
						mainOperatorOutput,
						operatorEventDispatcher);

				OP mainOperator = mainOperatorAndTimeService.f0;
				mainOperator.getMetricGroup().gauge(MetricNames.IO_CURRENT_OUTPUT_WATERMARK, mainOperatorOutput.getWatermarkGauge());
				this.mainOperatorWrapper = createOperatorWrapper(mainOperator, containingTask, configuration, mainOperatorAndTimeService.f1, true);

				// add main operator to end of chain
				allOpWrappers.add(mainOperatorWrapper);

				this.tailOperatorWrapper = allOpWrappers.get(0);
			} else {
				checkState(allOpWrappers.size() == 0);
				this.mainOperatorWrapper = null;
				this.tailOperatorWrapper = null;
			}

			this.chainedSources = createChainedSources(
				containingTask,
				configuration.getInputs(userCodeClassloader),
				chainedConfigs,
				userCodeClassloader,
				allOpWrappers);

			this.numOperators = allOpWrappers.size();

			firstOperatorWrapper = linkOperatorWrappers(allOpWrappers);

			success = true;
		}
		finally {
			// make sure we clean up after ourselves in case of a failure after acquiring
			// the first resources
			if (!success) {
				for (RecordWriterOutput<?> output : this.streamOutputs) {
					if (output != null) {
						output.close();
					}
				}
			}
		}
	}

	@VisibleForTesting
	OperatorChain(
			List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,
			RecordWriterOutput<?>[] streamOutputs,
			WatermarkGaugeExposingOutput<StreamRecord<OUT>> mainOperatorOutput,
			StreamOperatorWrapper<OUT, OP> mainOperatorWrapper) {

		this.streamOutputs = checkNotNull(streamOutputs);
		this.mainOperatorOutput = checkNotNull(mainOperatorOutput);
		this.operatorEventDispatcher = null;

		checkState(allOperatorWrappers != null && allOperatorWrappers.size() > 0);
		this.mainOperatorWrapper = checkNotNull(mainOperatorWrapper);
		this.tailOperatorWrapper = allOperatorWrappers.get(0);
		this.numOperators = allOperatorWrappers.size();
		this.chainedSources = Collections.emptyMap();

		firstOperatorWrapper = linkOperatorWrappers(allOperatorWrappers);
	}

	private void createChainOutputs(
			List<StreamEdge> outEdgesInOrder,
			RecordWriterDelegate<SerializationDelegate<StreamRecord<OUT>>> recordWriterDelegate,
			Map<Integer, StreamConfig> chainedConfigs,
			StreamTask<OUT, OP> containingTask,
			Map<StreamEdge, RecordWriterOutput<?>> streamOutputMap) {
		for (int i = 0; i < outEdgesInOrder.size(); i++) {
			StreamEdge outEdge = outEdgesInOrder.get(i);

			RecordWriterOutput<?> streamOutput = createStreamOutput(
				recordWriterDelegate.getRecordWriter(i),
				outEdge,
				chainedConfigs.get(outEdge.getSourceId()),
				containingTask.getEnvironment());

			this.streamOutputs[i] = streamOutput;
			streamOutputMap.put(outEdge, streamOutput);
		}
	}

	@SuppressWarnings("rawtypes")
	private Map<SourceInputConfig, ChainedSource> createChainedSources(
			StreamTask<OUT, OP> containingTask,
			InputConfig[] configuredInputs,
			Map<Integer, StreamConfig> chainedConfigs,
			ClassLoader userCodeClassloader,
			List<StreamOperatorWrapper<?, ?>> allOpWrappers) {
		if (Arrays.stream(configuredInputs).noneMatch(input -> input instanceof SourceInputConfig)) {
			return Collections.emptyMap();
		}
		checkState(
			mainOperatorWrapper.getStreamOperator() instanceof MultipleInputStreamOperator,
			"Creating chained input is only supported with MultipleInputStreamOperator and MultipleInputStreamTask");
		Map<SourceInputConfig, ChainedSource> chainedSourceInputs = new HashMap<>();
		MultipleInputStreamOperator<?> multipleInputOperator = (MultipleInputStreamOperator<?>) mainOperatorWrapper.getStreamOperator();
		List<Input> operatorInputs = multipleInputOperator.getInputs();

		int sourceInputGateIndex = Arrays.stream(containingTask.getEnvironment().getAllInputGates())
			.mapToInt(IndexedInputGate::getInputGateIndex)
			.max()
			.orElse(-1) + 1;

		for (int inputId = 0; inputId < configuredInputs.length; inputId++) {
			if (!(configuredInputs[inputId] instanceof SourceInputConfig)) {
				continue;
			}
			SourceInputConfig sourceInput = (SourceInputConfig) configuredInputs[inputId];
			int sourceEdgeId = sourceInput.getInputEdge().getSourceId();
			StreamConfig sourceInputConfig = chainedConfigs.get(sourceEdgeId);
			OutputTag outputTag = sourceInput.getInputEdge().getOutputTag();

			WatermarkGaugeExposingOutput chainedSourceOutput = createChainedSourceOutput(
				containingTask,
				operatorInputs.get(inputId),
				(OperatorMetricGroup) multipleInputOperator.getMetricGroup(),
				outputTag);

			SourceOperator<?, ?> sourceOperator = (SourceOperator<?, ?>) createOperator(
				containingTask,
				sourceInputConfig,
				userCodeClassloader,
				(WatermarkGaugeExposingOutput<StreamRecord<OUT>>) chainedSourceOutput,
				allOpWrappers,
				true);
			chainedSourceInputs.put(
				sourceInput,
				new ChainedSource(
					chainedSourceOutput,
					new StreamTaskSourceInput<>(sourceOperator, sourceInputGateIndex++, inputId)));
		}
		return chainedSourceInputs;
	}

	@SuppressWarnings("rawtypes")
	private WatermarkGaugeExposingOutput<StreamRecord> createChainedSourceOutput(
			StreamTask<?, OP> containingTask,
			Input input,
			OperatorMetricGroup metricGroup,
			OutputTag outputTag) {
		if (!containingTask.getExecutionConfig().isObjectReuseEnabled()) {
			throw new UnsupportedOperationException("Currently chained sources are supported only with objectReuse enabled");
		}
		/**
		 * Chained sources are closed when {@link org.apache.flink.streaming.runtime.io.StreamTaskSourceInput}
		 * are being closed.
		 */
		return new ChainingOutput<>(
			input,
			metricGroup,
			this,
			outputTag,
			null);
	}

	@Override
	public StreamStatus getStreamStatus() {
		return streamStatus;
	}

	public OperatorEventDispatcher getOperatorEventDispatcher() {
		return operatorEventDispatcher;
	}

	public void dispatchOperatorEvent(OperatorID operator, SerializedValue<OperatorEvent> event) throws FlinkException {
		operatorEventDispatcher.dispatchEventToHandlers(operator, event);
	}

	@Override
	public void toggleStreamStatus(StreamStatus status) {
		if (!status.equals(this.streamStatus)) {
			this.streamStatus = status;

			// try and forward the stream status change to all outgoing connections
			for (RecordWriterOutput<?> streamOutput : streamOutputs) {
				streamOutput.emitStreamStatus(status);
			}
		}
	}

	public void broadcastEvent(AbstractEvent event) throws IOException {
		broadcastEvent(event, false);
	}

	public void broadcastEvent(AbstractEvent event, boolean isPriorityEvent) throws IOException {
		for (RecordWriterOutput<?> streamOutput : streamOutputs) {
			streamOutput.broadcastEvent(event, isPriorityEvent);
		}
	}

	public void prepareSnapshotPreBarrier(long checkpointId) throws Exception {
		// go forward through the operator chain and tell each operator
		// to prepare the checkpoint
		for (StreamOperatorWrapper<?, ?> operatorWrapper : getAllOperators()) {
			if (!operatorWrapper.isClosed()) {
				operatorWrapper.getStreamOperator().prepareSnapshotPreBarrier(checkpointId);
			}
		}
	}

	/**
	 * Ends the main operator input specified by {@code inputId}).
	 *
	 * @param inputId the input ID starts from 1 which indicates the first input.
	 */
	public void endMainOperatorInput(int inputId) throws Exception {
		if (mainOperatorWrapper != null) {
			mainOperatorWrapper.endOperatorInput(inputId);
		}
	}

	/**
	 * Initialize state and open all operators in the chain from <b>tail to heads</b>,
	 * contrary to {@link StreamOperator#close()} which happens <b>heads to tail</b>
	 * (see {@link #closeOperators(StreamTaskActionExecutor)}).
	 */
	protected void initializeStateAndOpenOperators(StreamTaskStateInitializer streamTaskStateInitializer) throws Exception {
		for (StreamOperatorWrapper<?, ?> operatorWrapper : getAllOperators(true)) {
			StreamOperator<?> operator = operatorWrapper.getStreamOperator();
			operator.initializeState(streamTaskStateInitializer);
			operator.open();
		}
	}

	/**
	 * Closes all operators in a chain effect way. Closing happens from <b>heads to tail</b> operator
	 * in the chain, contrary to {@link StreamOperator#open()} which happens <b>tail to heads</b>
	 * (see {@link #initializeStateAndOpenOperators(StreamTaskStateInitializer)}).
	 */
	protected void closeOperators(StreamTaskActionExecutor actionExecutor) throws Exception {
		if (firstOperatorWrapper != null) {
			firstOperatorWrapper.close(actionExecutor);
		}
	}

	public RecordWriterOutput<?>[] getStreamOutputs() {
		return streamOutputs;
	}

	/**
	 * Returns an {@link Iterable} which traverses all operators in forward topological order.
	 */
	public Iterable<StreamOperatorWrapper<?, ?>> getAllOperators() {
		return getAllOperators(false);
	}

	/**
	 * Returns an {@link Iterable} which traverses all operators in forward or reverse
	 * topological order.
	 */
	public Iterable<StreamOperatorWrapper<?, ?>> getAllOperators(boolean reverse) {
		return reverse ?
			new StreamOperatorWrapper.ReadIterator(tailOperatorWrapper, true) :
			new StreamOperatorWrapper.ReadIterator(mainOperatorWrapper, false);
	}

	public int getNumberOfOperators() {
		return numOperators;
	}

	public WatermarkGaugeExposingOutput<StreamRecord<OUT>> getMainOperatorOutput() {
		return mainOperatorOutput;
	}

	public Output<StreamRecord<?>> getChainedSourceOutput(SourceInputConfig sourceInput) {
		checkArgument(
			chainedSources.containsKey(sourceInput),
			"Chained source with sourcedId = [%s] was not found",
			sourceInput);
		return chainedSources.get(sourceInput).getSourceOutput();
	}

	public StreamTaskSourceInput<?> getSourceTaskInput(SourceInputConfig sourceInput) {
		checkArgument(
			chainedSources.containsKey(sourceInput),
			"Chained source with sourcedId = [%s] was not found",
			sourceInput);
		return chainedSources.get(sourceInput).getSourceTaskInput();
	}

	public List<StreamTaskSourceInput<?>> getSourceTaskInputs() {
		return chainedSources.values()
			.stream()
			.map(ChainedSource::getSourceTaskInput)
			.collect(Collectors.toList());
	}

	/**
	 * This method should be called before finishing the record emission, to make sure any data
	 * that is still buffered will be sent. It also ensures that all data sending related
	 * exceptions are recognized.
	 *
	 * @throws IOException Thrown, if the buffered data cannot be pushed into the output streams.
	 */
	public void flushOutputs() throws IOException {
		for (RecordWriterOutput<?> streamOutput : getStreamOutputs()) {
			streamOutput.flush();
		}
	}

	/**
	 * This method releases all resources of the record writer output. It stops the output
	 * flushing thread (if there is one) and releases all buffers currently held by the output
	 * serializers.
	 *
	 * <p>This method should never fail.
	 */
	public void releaseOutputs() {
		for (RecordWriterOutput<?> streamOutput : streamOutputs) {
			streamOutput.close();
		}
	}

	@Nullable
	public OP getMainOperator() {
		return (mainOperatorWrapper == null) ? null : mainOperatorWrapper.getStreamOperator();
	}

	// ------------------------------------------------------------------------
	//  initialization utilities
	// ------------------------------------------------------------------------

	private <T> WatermarkGaugeExposingOutput<StreamRecord<T>> createOutputCollector(
			StreamTask<?, ?> containingTask,
			StreamConfig operatorConfig,
			Map<Integer, StreamConfig> chainedConfigs,
			ClassLoader userCodeClassloader,
			Map<StreamEdge, RecordWriterOutput<?>> streamOutputs,
			List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,
			MailboxExecutorFactory mailboxExecutorFactory) {
		List<Tuple2<WatermarkGaugeExposingOutput<StreamRecord<T>>, StreamEdge>> allOutputs = new ArrayList<>(4);

		// create collectors for the network outputs
		for (StreamEdge outputEdge : operatorConfig.getNonChainedOutputs(userCodeClassloader)) {
			@SuppressWarnings("unchecked")
			RecordWriterOutput<T> output = (RecordWriterOutput<T>) streamOutputs.get(outputEdge);

			allOutputs.add(new Tuple2<>(output, outputEdge));
		}

		// Create collectors for the chained outputs
		for (StreamEdge outputEdge : operatorConfig.getChainedOutputs(userCodeClassloader)) {
			int outputId = outputEdge.getTargetId();
			StreamConfig chainedOpConfig = chainedConfigs.get(outputId);

			WatermarkGaugeExposingOutput<StreamRecord<T>> output = createOperatorChain(
				containingTask,
				chainedOpConfig,
				chainedConfigs,
				userCodeClassloader,
				streamOutputs,
				allOperatorWrappers,
				outputEdge.getOutputTag(),
				mailboxExecutorFactory);
			allOutputs.add(new Tuple2<>(output, outputEdge));
		}

		if (allOutputs.size() == 1) {
			return allOutputs.get(0).f0;
		} else {
			// send to N outputs. Note that this includes the special case
			// of sending to zero outputs
			@SuppressWarnings({"unchecked"})
			Output<StreamRecord<T>>[] asArray = new Output[allOutputs.size()];
			for (int i = 0; i < allOutputs.size(); i++) {
				asArray[i] = allOutputs.get(i).f0;
			}

			// This is the inverse of creating the normal ChainingOutput.
			// If the chaining output does not copy we need to copy in the broadcast output,
			// otherwise multi-chaining would not work correctly.
			if (containingTask.getExecutionConfig().isObjectReuseEnabled()) {
				return new CopyingBroadcastingOutputCollector<>(asArray, this);
			} else {
				return new BroadcastingOutputCollector<>(asArray, this);
			}
		}
	}

	/**
	 * Recursively create chain of operators that starts from the given {@param operatorConfig}.
	 * Operators are created tail to head and wrapped into an {@link WatermarkGaugeExposingOutput}.
	 */
	private <IN, OUT> WatermarkGaugeExposingOutput<StreamRecord<IN>> createOperatorChain(
			StreamTask<OUT, ?> containingTask,
			StreamConfig operatorConfig,
			Map<Integer, StreamConfig> chainedConfigs,
			ClassLoader userCodeClassloader,
			Map<StreamEdge, RecordWriterOutput<?>> streamOutputs,
			List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,
			OutputTag<IN> outputTag,
			MailboxExecutorFactory mailboxExecutorFactory) {
		// create the output that the operator writes to first. this may recursively create more operators
		WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainedOperatorOutput = createOutputCollector(
			containingTask,
			operatorConfig,
			chainedConfigs,
			userCodeClassloader,
			streamOutputs,
			allOperatorWrappers,
			mailboxExecutorFactory);

		OneInputStreamOperator<IN, OUT> chainedOperator = createOperator(
			containingTask,
			operatorConfig,
			userCodeClassloader,
			chainedOperatorOutput,
			allOperatorWrappers,
			false);

		return wrapOperatorIntoOutput(
			chainedOperator,
			containingTask,
			operatorConfig,
			userCodeClassloader,
			outputTag);
	}

	/**
	 * Create and return a single operator from the given {@param operatorConfig} that will be producing
	 * records to the {@param output}.
	 */
	private <OUT, OP extends StreamOperator<OUT>> OP createOperator(
			StreamTask<OUT, ?> containingTask,
			StreamConfig operatorConfig,
			ClassLoader userCodeClassloader,
			WatermarkGaugeExposingOutput<StreamRecord<OUT>> output,
			List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,
			boolean isHead) {

		// now create the operator and give it the output collector to write its output to
		Tuple2<OP, Optional<ProcessingTimeService>> chainedOperatorAndTimeService =
			StreamOperatorFactoryUtil.createOperator(
				operatorConfig.getStreamOperatorFactory(userCodeClassloader),
				containingTask,
				operatorConfig,
				output,
				operatorEventDispatcher);

		OP chainedOperator = chainedOperatorAndTimeService.f0;
		allOperatorWrappers.add(createOperatorWrapper(chainedOperator, containingTask, operatorConfig, chainedOperatorAndTimeService.f1, isHead));

		chainedOperator.getMetricGroup().gauge(MetricNames.IO_CURRENT_OUTPUT_WATERMARK, output.getWatermarkGauge()::getValue);
		return chainedOperator;
	}

	private <IN, OUT> WatermarkGaugeExposingOutput<StreamRecord<IN>> wrapOperatorIntoOutput(
			OneInputStreamOperator<IN, OUT> operator,
			StreamTask<OUT, ?> containingTask,
			StreamConfig operatorConfig,
			ClassLoader userCodeClassloader,
			OutputTag<IN> outputTag) {

		WatermarkGaugeExposingOutput<StreamRecord<IN>> currentOperatorOutput;
		if (containingTask.getExecutionConfig().isObjectReuseEnabled()) {
			currentOperatorOutput = new ChainingOutput<>(operator, this, outputTag);
		}
		else {
			TypeSerializer<IN> inSerializer = operatorConfig.getTypeSerializerIn1(userCodeClassloader);
			currentOperatorOutput = new CopyingChainingOutput<>(operator, inSerializer, outputTag, this);
		}

		// wrap watermark gauges since registered metrics must be unique
		operator.getMetricGroup().gauge(MetricNames.IO_CURRENT_INPUT_WATERMARK, currentOperatorOutput.getWatermarkGauge()::getValue);

		return currentOperatorOutput;
	}

	private RecordWriterOutput<OUT> createStreamOutput(
			RecordWriter<SerializationDelegate<StreamRecord<OUT>>> recordWriter,
			StreamEdge edge,
			StreamConfig upStreamConfig,
			Environment taskEnvironment) {
		OutputTag sideOutputTag = edge.getOutputTag(); // OutputTag, return null if not sideOutput

		TypeSerializer outSerializer = null;

		if (edge.getOutputTag() != null) {
			// side output
			outSerializer = upStreamConfig.getTypeSerializerSideOut(
					edge.getOutputTag(), taskEnvironment.getUserCodeClassLoader().asClassLoader());
		} else {
			// main output
			outSerializer = upStreamConfig.getTypeSerializerOut(taskEnvironment.getUserCodeClassLoader().asClassLoader());
		}

		return new RecordWriterOutput<>(recordWriter, outSerializer, sideOutputTag, this);
	}

	/**
	 * Links operator wrappers in forward topological order.
	 *
	 * @param allOperatorWrappers is an operator wrapper list of reverse topological order
	 */
	private StreamOperatorWrapper<?, ?> linkOperatorWrappers(List<StreamOperatorWrapper<?, ?>> allOperatorWrappers) {
		StreamOperatorWrapper<?, ?> previous = null;
		for (StreamOperatorWrapper<?, ?> current : allOperatorWrappers) {
			if (previous != null) {
				previous.setPrevious(current);
			}
			current.setNext(previous);
			previous = current;
		}
		return previous;
	}

	private <T, P extends StreamOperator<T>> StreamOperatorWrapper<T, P> createOperatorWrapper(
			P operator,
			StreamTask<?, ?> containingTask,
			StreamConfig operatorConfig,
			Optional<ProcessingTimeService> processingTimeService,
			boolean isHead) {
		return new StreamOperatorWrapper<>(
			operator,
			processingTimeService,
			containingTask.getMailboxExecutorFactory().createExecutor(operatorConfig.getChainIndex()),
			isHead);
	}

	@Nullable
	StreamOperator<?> getTailOperator() {
		return (tailOperatorWrapper == null) ? null : tailOperatorWrapper.getStreamOperator();
	}

	/**
	 * Wrapper class to access the chained sources and their's outputs.
	 */
	public static class ChainedSource {
		private final WatermarkGaugeExposingOutput<StreamRecord<?>> chainedSourceOutput;
		private final StreamTaskSourceInput<?> sourceTaskInput;

		public ChainedSource(
				WatermarkGaugeExposingOutput<StreamRecord<?>> chainedSourceOutput,
				StreamTaskSourceInput<?> sourceTaskInput) {
			this.chainedSourceOutput = chainedSourceOutput;
			this.sourceTaskInput = sourceTaskInput;
		}

		public Output<StreamRecord<?>> getSourceOutput() {
			return chainedSourceOutput;
		}

		public StreamTaskSourceInput<?> getSourceTaskInput() {
			return sourceTaskInput;
		}
	}
}
