== Abstract Syntax Tree ==
Select(GroupBy(As(Root(ArraySeq((count,Integer), (word,String))), a,b), 'a), 'a,('b).count as 'c)

== Physical Execution Plan ==
Stage 6 : Data Source
	content : collect elements with CollectionInputFormat
	Partitioning : RANDOM_PARTITIONED

	Stage 5 : Map
		content : Map at select('count as 'count,'word as 'word)
		ship_strategy : Forward
		exchange_mode : PIPELINED
		driver_strategy : Map
		Partitioning : RANDOM_PARTITIONED

		Stage 4 : Map
			content : Map at select(1 as 'intermediate.1,'a as 'a)
			ship_strategy : Forward
			exchange_mode : PIPELINED
			driver_strategy : Map
			Partitioning : RANDOM_PARTITIONED

			Stage 3 : GroupCombine
				content : GroupReduce at Expression Aggregation: Aggregate(GroupBy(Select(As(Root(ArraySeq((count,Integer), (word,String))), a,b), 1 as 'intermediate.1,'a as 'a), 'a), (intermediate.1,SUM))
				ship_strategy : Forward
				exchange_mode : PIPELINED
				driver_strategy : Sorted Combine
				Partitioning : RANDOM_PARTITIONED

				Stage 2 : GroupReduce
					content : GroupReduce at Expression Aggregation: Aggregate(GroupBy(Select(As(Root(ArraySeq((count,Integer), (word,String))), a,b), 1 as 'intermediate.1,'a as 'a), 'a), (intermediate.1,SUM))
					ship_strategy : Hash Partition on [1]
					exchange_mode : PIPELINED
					driver_strategy : Sorted Group Reduce
					Partitioning : RANDOM_PARTITIONED

					Stage 1 : Map
						content : Map at select('a,'intermediate.1 as 'result.1 as 'c)
						ship_strategy : Forward
						exchange_mode : PIPELINED
						driver_strategy : Map
						Partitioning : RANDOM_PARTITIONED

						Stage 0 : Data Sink
							content : org.apache.flink.api.java.io.DiscardingOutputFormat
							ship_strategy : Forward
							exchange_mode : PIPELINED
							Partitioning : RANDOM_PARTITIONED

