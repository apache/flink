<table class="configuration table table-bordered">
    <thead>
        <tr>
            <th class="text-left" style="width: 20%">Key</th>
            <th class="text-left" style="width: 15%">Default</th>
            <th class="text-left" style="width: 10%">Type</th>
            <th class="text-left" style="width: 55%">Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><h5>jobmanager.adaptive-scheduler.min-parallelism-increase</h5></td>
            <td style="word-wrap: break-word;">1</td>
            <td>Integer</td>
            <td>Configure the minimum increase in parallelism for a job to scale up.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.adaptive-scheduler.resource-stabilization-timeout</h5></td>
            <td style="word-wrap: break-word;">10 s</td>
            <td>Duration</td>
            <td>The resource stabilization timeout defines the time the JobManager will wait if fewer than the desired but sufficient resources are available. The timeout starts once sufficient resources for running the job are available. Once this timeout has passed, the job will start executing with the available resources.<br />If <code class="highlighter-rouge">scheduler-mode</code> is configured to <code class="highlighter-rouge">REACTIVE</code>, this configuration value will default to 0, so that jobs are starting immediately with the available resources.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.adaptive-scheduler.resource-wait-timeout</h5></td>
            <td style="word-wrap: break-word;">5 min</td>
            <td>Duration</td>
            <td>The maximum time the JobManager will wait to acquire all required resources after a job submission or restart. Once elapsed it will try to run the job with a lower parallelism, or fail if the minimum amount of resources could not be acquired.<br />Increasing this value will make the cluster more resilient against temporary resources shortages (e.g., there is more time for a failed TaskManager to be restarted).<br />Setting a negative duration will disable the resource timeout: The JobManager will wait indefinitely for resources to appear.<br />If <code class="highlighter-rouge">scheduler-mode</code> is configured to <code class="highlighter-rouge">REACTIVE</code>, this configuration value will default to a negative value to disable the resource timeout.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.adaptive-scheduler.scaling-interval.max</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Duration</td>
            <td>Determines the maximum interval time after which a scaling operation is forced even if the <code class="highlighter-rouge">jobmanager.adaptive-scheduler.min-parallelism-increase</code> aren't met. The scaling operation will be ignored when the resource hasn't changed. This option is disabled by default.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.adaptive-scheduler.scaling-interval.min</h5></td>
            <td style="word-wrap: break-word;">30 s</td>
            <td>Duration</td>
            <td>Determines the minimum time between scaling operations.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.archive.fs.dir</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>Directory for JobManager to store the archives of completed jobs.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.bind-host</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>The local address of the network interface that the job manager binds to. If not configured, '0.0.0.0' will be used.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.execution.attempts-history-size</h5></td>
            <td style="word-wrap: break-word;">16</td>
            <td>Integer</td>
            <td>The maximum number of historical execution attempts kept in history.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.execution.failover-strategy</h5></td>
            <td style="word-wrap: break-word;">"region"</td>
            <td>String</td>
            <td>This option specifies how the job computation recovers from task failures. Accepted values are:<ul><li>'full': Restarts all tasks to recover the job.</li><li>'region': Restarts all tasks that could be affected by the task failure. More details can be found <a href="{{.Site.BaseURL}}{{.Site.LanguagePrefix}}/docs/ops/state/task_failure_recovery/#restart-pipelined-region-failover-strategy">here</a>.</li></ul></td>
        </tr>
        <tr>
            <td><h5>jobmanager.failure-enrichers</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>An optional list of failure enricher names. If empty, NO failure enrichers will be started. If configured, only enrichers whose name matches any of the names in the list will be started.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.future-pool.size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>The size of the future thread pool to execute future callbacks for all spawned JobMasters. If no value is specified, then Flink defaults to the number of available CPU cores.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.io-pool.size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>The size of the IO thread pool to run blocking operations for all spawned JobMasters. This includes recovery and completion of checkpoints. Increase this value if you experience slow checkpoint operations when running many jobs. If no value is specified, then Flink defaults to the number of available CPU cores.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.enable-jvm-direct-memory-limit</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>Whether to enable the JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize). The limit will be set to the value of 'jobmanager.memory.off-heap.size' option. </td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.flink.size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>MemorySize</td>
            <td>Total Flink Memory size for the JobManager. This includes all the memory that a JobManager consumes, except for JVM Metaspace and JVM Overhead. It consists of JVM Heap Memory and Off-heap Memory. See also 'jobmanager.memory.process.size' for total process memory size configuration.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.heap.size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>MemorySize</td>
            <td>JVM Heap Memory size for JobManager. The minimum recommended JVM Heap size is 128.000mb (134217728 bytes).</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.jvm-metaspace.size</h5></td>
            <td style="word-wrap: break-word;">256 mb</td>
            <td>MemorySize</td>
            <td>JVM Metaspace Size for the JobManager.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.jvm-overhead.fraction</h5></td>
            <td style="word-wrap: break-word;">0.1</td>
            <td>Float</td>
            <td>Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.jvm-overhead.max</h5></td>
            <td style="word-wrap: break-word;">1 gb</td>
            <td>MemorySize</td>
            <td>Max JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.jvm-overhead.min</h5></td>
            <td style="word-wrap: break-word;">192 mb</td>
            <td>MemorySize</td>
            <td>Min JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.off-heap.size</h5></td>
            <td style="word-wrap: break-word;">128 mb</td>
            <td>MemorySize</td>
            <td>Off-heap Memory size for JobManager. This option covers all off-heap memory usage including direct and native memory allocation. The JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize) will be set to this value if the limit is enabled by 'jobmanager.memory.enable-jvm-direct-memory-limit'. </td>
        </tr>
        <tr>
            <td><h5>jobmanager.memory.process.size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>MemorySize</td>
            <td>Total Process Memory size for the JobManager. This includes all the memory that a JobManager JVM process consumes, consisting of Total Flink Memory, JVM Metaspace, and JVM Overhead. In containerized setups, this should be set to the container memory. See also 'jobmanager.memory.flink.size' for Total Flink Memory size configuration.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.partition.hybrid.partition-data-consume-constraint</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td><p>Enum</p></td>
            <td>Controls the constraint that hybrid partition data can be consumed. Note that this option is allowed only when <code class="highlighter-rouge">jobmanager.scheduler</code> has been set to <code class="highlighter-rouge">AdaptiveBatch</code>. Accepted values are:<ul><li>'<code class="highlighter-rouge">ALL_PRODUCERS_FINISHED</code>': hybrid partition data can be consumed only when all producers are finished.</li><li>'<code class="highlighter-rouge">ONLY_FINISHED_PRODUCERS</code>': hybrid partition data can be consumed when its producer is finished.</li><li>'<code class="highlighter-rouge">UNFINISHED_PRODUCERS</code>': hybrid partition data can be consumed even if its producer is un-finished.</li></ul><br /><br />Possible values:<ul><li>"ALL_PRODUCERS_FINISHED"</li><li>"ONLY_FINISHED_PRODUCERS"</li><li>"UNFINISHED_PRODUCERS"</li></ul></td>
        </tr>
        <tr>
            <td><h5>jobmanager.resource-id</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>The JobManager's ResourceID. If not configured, the ResourceID will be generated randomly.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.retrieve-taskmanager-hostname</h5></td>
            <td style="word-wrap: break-word;">true</td>
            <td>Boolean</td>
            <td>Flag indicating whether JobManager would retrieve canonical host name of TaskManager during registration. If the option is set to "false", TaskManager registration with JobManager could be faster, since no reverse DNS lookup is performed. However, local input split assignment (such as for HDFS files) may be impacted.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.rpc.address</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>The config parameter defining the network address to connect to for communication with the job manager. This value is only interpreted in setups where a single JobManager with static name or address exists (simple standalone setups, or container setups with dynamic service name resolution). It is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.rpc.bind-port</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>The local RPC port that the JobManager binds to. If not configured, the external port (configured by 'jobmanager.rpc.port') will be used.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.rpc.port</h5></td>
            <td style="word-wrap: break-word;">6123</td>
            <td>Integer</td>
            <td>The config parameter defining the network port to connect to for communication with the job manager. Like jobmanager.rpc.address, this value is only interpreted in setups where a single JobManager with static name/address and port exists (simple standalone setups, or container setups with dynamic service name resolution). This config option is not used in many high-availability setups, when a leader-election service (like ZooKeeper) is used to elect and discover the JobManager leader from potentially multiple standby JobManagers.</td>
        </tr>
        <tr>
            <td><h5>jobmanager.scheduler</h5></td>
            <td style="word-wrap: break-word;">Default</td>
            <td><p>Enum</p></td>
            <td>Determines which scheduler implementation is used to schedule tasks. Accepted values are:<ul><li>'Default': Default scheduler</li><li>'Adaptive': Adaptive scheduler. More details can be found <a href="{{.Site.BaseURL}}{{.Site.LanguagePrefix}}/docs/deployment/elastic_scaling#adaptive-scheduler">here</a>.</li><li>'AdaptiveBatch': Adaptive batch scheduler. More details can be found <a href="{{.Site.BaseURL}}{{.Site.LanguagePrefix}}/docs/deployment/elastic_scaling#adaptive-batch-scheduler">here</a>.</li></ul><br /><br />Possible values:<ul><li>"Default"</li><li>"Adaptive"</li><li>"AdaptiveBatch"</li></ul></td>
        </tr>
        <tr>
            <td><h5>jobstore.cache-size</h5></td>
            <td style="word-wrap: break-word;">52428800</td>
            <td>Long</td>
            <td>The job store cache size in bytes which is used to keep completed jobs in memory.</td>
        </tr>
        <tr>
            <td><h5>jobstore.expiration-time</h5></td>
            <td style="word-wrap: break-word;">3600</td>
            <td>Long</td>
            <td>The time in seconds after which a completed job expires and is purged from the job store.</td>
        </tr>
        <tr>
            <td><h5>jobstore.max-capacity</h5></td>
            <td style="word-wrap: break-word;">infinite</td>
            <td>Integer</td>
            <td>The max number of completed jobs that can be kept in the job store. NOTICE: if memory store keeps too many jobs in session cluster, it may cause FullGC or OOM in jm.</td>
        </tr>
        <tr>
            <td><h5>jobstore.type</h5></td>
            <td style="word-wrap: break-word;">File</td>
            <td><p>Enum</p></td>
            <td>Determines which job store implementation is used in session cluster. Accepted values are:<ul><li>'File': the file job store keeps the archived execution graphs in files</li><li>'Memory': the memory job store keeps the archived execution graphs in memory. You may need to limit the <code class="highlighter-rouge">jobstore.max-capacity</code> to mitigate FullGC or OOM when there are too many graphs</li></ul><br /><br />Possible values:<ul><li>"File"</li><li>"Memory"</li></ul></td>
        </tr>
        <tr>
            <td><h5>scheduler-mode</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td><p>Enum</p></td>
            <td>Determines the mode of the scheduler. Note that <code class="highlighter-rouge">scheduler-mode</code>=<code class="highlighter-rouge">REACTIVE</code> is only supported by standalone application deployments, not by active resource managers (YARN, Kubernetes) or session clusters.<br /><br />Possible values:<ul><li>"REACTIVE"</li></ul></td>
        </tr>
        <tr>
            <td><h5>slot.idle.timeout</h5></td>
            <td style="word-wrap: break-word;">50000</td>
            <td>Long</td>
            <td>The timeout in milliseconds for a idle slot in Slot Pool.</td>
        </tr>
        <tr>
            <td><h5>slot.request.timeout</h5></td>
            <td style="word-wrap: break-word;">300000</td>
            <td>Long</td>
            <td>The timeout in milliseconds for requesting a slot from Slot Pool.</td>
        </tr>
    </tbody>
</table>
