Constructor <org.apache.flink.runtime.scheduler.exceptionhistory.ExceptionHistoryEntry.<init>(java.lang.Throwable, long, java.lang.String, org.apache.flink.runtime.taskmanager.TaskManagerLocation)> calls method <org.apache.flink.runtime.scheduler.exceptionhistory.ExceptionHistoryEntry$ArchivedTaskManagerLocation.fromTaskManagerLocation(org.apache.flink.runtime.taskmanager.TaskManagerLocation)> in (ExceptionHistoryEntry.java:90)
Constructor <org.apache.flink.runtime.state.heap.CopyOnWriteStateMapSnapshot.<init>(org.apache.flink.runtime.state.heap.CopyOnWriteStateMap)> calls method <org.apache.flink.runtime.state.heap.CopyOnWriteStateMap.snapshotMapArrays()> in (CopyOnWriteStateMapSnapshot.java:86)
Constructor <org.apache.flink.streaming.api.operators.StreamingRuntimeContext.<init>(org.apache.flink.streaming.api.operators.AbstractStreamOperator, org.apache.flink.runtime.execution.Environment, java.util.Map)> calls method <org.apache.flink.streaming.api.operators.AbstractStreamOperator.getProcessingTimeService()> in (StreamingRuntimeContext.java:85)
Constructor <org.apache.flink.streaming.runtime.io.StreamTaskExternallyInducedSourceInput.<init>(org.apache.flink.streaming.api.operators.SourceOperator, java.util.function.Consumer, int, int)> calls method <org.apache.flink.streaming.api.operators.SourceOperator.getSourceReader()> in (StreamTaskExternallyInducedSourceInput.java:39)
Constructor <org.apache.flink.table.catalog.hive.client.HiveMetastoreClientWrapper.<init>(org.apache.hadoop.hive.conf.HiveConf, org.apache.flink.table.catalog.hive.client.HiveShim)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isEmbeddedMetastore(org.apache.hadoop.hive.conf.HiveConf)> in (HiveMetastoreClientWrapper.java:76)
Method <org.apache.flink.api.java.typeutils.runtime.TupleSerializerSnapshot.getNestedSerializers(org.apache.flink.api.java.typeutils.runtime.TupleSerializer)> calls method <org.apache.flink.api.java.typeutils.runtime.TupleSerializer.getFieldSerializers()> in (TupleSerializerSnapshot.java:70)
Method <org.apache.flink.connector.kafka.source.reader.KafkaSourceReader.getNumAliveFetchers()> calls method <org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.getNumAliveFetchers()> in (KafkaSourceReader.java:193)
Method <org.apache.flink.connectors.hive.HiveDynamicTableFactory.createDynamicTableSink(org.apache.flink.table.factories.DynamicTableFactory$Context)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isHiveTable(java.util.Map)> in (HiveDynamicTableFactory.java:69)
Method <org.apache.flink.connectors.hive.HiveDynamicTableFactory.createDynamicTableSource(org.apache.flink.table.factories.DynamicTableFactory$Context)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isHiveTable(java.util.Map)> in (HiveDynamicTableFactory.java:99)
Method <org.apache.flink.connectors.hive.HiveTableFactory.createTableSink(org.apache.flink.table.factories.TableSinkFactory$Context)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isHiveTable(java.util.Map)> in (HiveTableFactory.java:70)
Method <org.apache.flink.connectors.hive.HiveTableFactory.createTableSource(org.apache.flink.table.factories.TableSourceFactory$Context)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isHiveTable(java.util.Map)> in (HiveTableFactory.java:54)
Method <org.apache.flink.orc.nohive.shim.OrcNoHiveShim.createRecordReader(org.apache.hadoop.conf.Configuration, org.apache.orc.TypeDescription, [I, java.util.List, org.apache.flink.core.fs.Path, long, long)> calls method <org.apache.flink.orc.shim.OrcShimV200.getOffsetAndLengthForSplit(long, long, java.util.List)> in (OrcNoHiveShim.java:62)
Method <org.apache.flink.runtime.blob.BlobInputStream.read()> calls method <org.apache.flink.runtime.blob.BlobKey.getHash()> in (BlobInputStream.java:127)
Method <org.apache.flink.runtime.blob.BlobInputStream.read([B, int, int)> calls method <org.apache.flink.runtime.blob.BlobKey.getHash()> in (BlobInputStream.java:163)
Method <org.apache.flink.runtime.blob.BlobOutputStream.receiveAndCheckPutResponse(java.io.InputStream, java.security.MessageDigest, org.apache.flink.runtime.blob.BlobKey$BlobType)> calls method <org.apache.flink.runtime.blob.BlobKey.getHash()> in (BlobOutputStream.java:155)
Method <org.apache.flink.runtime.blob.BlobServerConnection.get(java.io.InputStream, java.io.OutputStream, [B)> calls method <org.apache.flink.runtime.blob.BlobServer.getStorageLocation(org.apache.flink.api.common.JobID, org.apache.flink.runtime.blob.BlobKey)> in (BlobServerConnection.java:200)
Method <org.apache.flink.runtime.blob.FileSystemBlobStore.get(java.lang.String, java.io.File, org.apache.flink.runtime.blob.BlobKey)> calls method <org.apache.flink.runtime.blob.BlobKey.getHash()> in (FileSystemBlobStore.java:122)
Method <org.apache.flink.runtime.checkpoint.CheckpointCoordinator.getTriggerRequestQueue()> calls method <org.apache.flink.runtime.checkpoint.CheckpointRequestDecider.getTriggerRequestQueue()> in (CheckpointCoordinator.java:1735)
Method <org.apache.flink.runtime.executiongraph.Execution.finishPartitionsAndUpdateConsumers()> calls method <org.apache.flink.runtime.executiongraph.ExecutionVertex.finishAllBlockingPartitions()> in (Execution.java:974)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.grantDispatcherLeadership()> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.grantLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:67)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.grantJobMasterLeadership(org.apache.flink.api.common.JobID)> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.grantLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:79)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.grantResourceManagerLeadership()> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.grantLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:93)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.lambda$new$0(java.lang.Integer, org.apache.flink.runtime.checkpoint.EmbeddedCompletedCheckpointStore)> calls method <org.apache.flink.runtime.checkpoint.EmbeddedCompletedCheckpointStore.getShutdownStatus()> in (EmbeddedHaServicesWithLeadershipControl.java:41)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.revokeDispatcherLeadership()> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.revokeLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:61)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.revokeJobMasterLeadership(org.apache.flink.api.common.JobID)> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.revokeLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:73)
Method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServicesWithLeadershipControl.revokeResourceManagerLeadership()> calls method <org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService.revokeLeadership()> in (EmbeddedHaServicesWithLeadershipControl.java:86)
Method <org.apache.flink.runtime.io.network.partition.ResourceManagerPartitionTrackerImpl.lambda$listDataSets$10(java.util.Map$Entry)> calls method <org.apache.flink.runtime.io.network.partition.DataSetMetaInfo.withNumRegisteredPartitions(int, int)> in (ResourceManagerPartitionTrackerImpl.java:269)
Method <org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.getNumberOfAvailableBuffers()> calls method <org.apache.flink.runtime.io.network.partition.consumer.BufferManager.getNumberOfAvailableBuffers()> in (RemoteInputChannel.java:336)
Method <org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.getNumberOfRequiredBuffers()> calls method <org.apache.flink.runtime.io.network.partition.consumer.BufferManager.unsynchronizedGetNumberOfRequiredBuffers()> in (RemoteInputChannel.java:341)
Method <org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel.isWaitingForFloatingBuffers()> calls method <org.apache.flink.runtime.io.network.partition.consumer.BufferManager.unsynchronizedIsWaitingForFloatingBuffers()> in (RemoteInputChannel.java:351)
Method <org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$DeferrableCoordinator.closeAsync(long)> calls method <org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.quiesce()> in (RecreateOnResetOperatorCoordinator.java:319)
Method <org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext, org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)> calls method <org.apache.flink.runtime.rest.RestServerEndpoint.createUploadDir(java.nio.file.Path, org.slf4j.Logger, boolean)> in (FileUploadHandler.java:132)
Method <org.apache.flink.runtime.rest.FileUploadHandler.channelRead0(org.apache.flink.shaded.netty4.io.netty.channel.ChannelHandlerContext, org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpObject)> calls method <org.apache.flink.runtime.rest.RestServerEndpoint.createUploadDir(java.nio.file.Path, org.slf4j.Logger, boolean)> in (FileUploadHandler.java:147)
Method <org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.numKeyValueStateEntries(java.lang.Object)> calls method <org.apache.flink.runtime.state.heap.StateTable.sizeOfNamespace(java.lang.Object)> in (HeapKeyedStateBackend.java:391)
Method <org.apache.flink.runtime.state.heap.StateTable.sizeOfNamespace(java.lang.Object)> calls method <org.apache.flink.runtime.state.heap.StateMap.sizeOfNamespace(java.lang.Object)> in (StateTable.java:361)
Method <org.apache.flink.runtime.taskexecutor.TaskExecutor.registerNewJobAndCreateServices(org.apache.flink.api.common.JobID, java.lang.String)> calls method <org.apache.flink.runtime.taskexecutor.TaskExecutor$TaskExecutorJobServices.create(org.apache.flink.runtime.execution.librarycache.LibraryCacheManager$ClassLoaderLease, java.lang.Runnable)> in (TaskExecutor.java:1121)
Method <org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration.fromConfiguration(org.apache.flink.configuration.Configuration, org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, java.lang.String)> calls method <org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.generateDefaultSlotResourceProfile(org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, int)> in (TaskManagerConfiguration.java:236)
Method <org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration.fromConfiguration(org.apache.flink.configuration.Configuration, org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, java.lang.String)> calls method <org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.generateTotalAvailableResourceProfile(org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec)> in (TaskManagerConfiguration.java:238)
Method <org.apache.flink.runtime.taskexecutor.TaskManagerServices.createTaskSlotTable(int, org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, long, int, java.util.concurrent.Executor)> calls method <org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.generateDefaultSlotResourceProfile(org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, int)> in (TaskManagerServices.java:387)
Method <org.apache.flink.runtime.taskexecutor.TaskManagerServices.createTaskSlotTable(int, org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec, long, int, java.util.concurrent.Executor)> calls method <org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils.generateTotalAvailableResourceProfile(org.apache.flink.runtime.taskexecutor.TaskExecutorResourceSpec)> in (TaskManagerServices.java:385)
Method <org.apache.flink.streaming.api.datastream.WindowedStream.getAllowedLateness()> calls method <org.apache.flink.streaming.runtime.operators.windowing.WindowOperatorBuilder.getAllowedLateness()> in (WindowedStream.java:907)
Method <org.apache.flink.streaming.api.operators.InternalTimeServiceManagerImpl.numEventTimeTimers()> calls method <org.apache.flink.streaming.api.operators.InternalTimerServiceImpl.numEventTimeTimers()> in (InternalTimeServiceManagerImpl.java:249)
Method <org.apache.flink.streaming.api.operators.InternalTimeServiceManagerImpl.numProcessingTimeTimers()> calls method <org.apache.flink.streaming.api.operators.InternalTimerServiceImpl.numProcessingTimeTimers()> in (InternalTimeServiceManagerImpl.java:240)
Method <org.apache.flink.streaming.api.operators.SourceOperator$1$1.asClassLoader()> calls method <org.apache.flink.streaming.api.operators.SourceOperator.getRuntimeContext()> in (SourceOperator.java:250)
Method <org.apache.flink.streaming.api.operators.SourceOperator$1$1.registerReleaseHookIfAbsent(java.lang.String, java.lang.Runnable)> calls method <org.apache.flink.streaming.api.operators.SourceOperator.getRuntimeContext()> in (SourceOperator.java:256)
Method <org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.getTransactionCoordinatorId()> calls method <org.apache.flink.streaming.connectors.kafka.internals.FlinkKafkaInternalProducer.getTransactionCoordinatorId()> in (FlinkKafkaProducer.java:1327)
Method <org.apache.flink.streaming.connectors.kafka.internals.KafkaShuffleFetcher.partitionConsumerRecordsHandler(java.util.List, org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionState)> calls method <org.apache.flink.streaming.connectors.kafka.internals.KafkaShuffleFetcher$KafkaShuffleElementDeserializer.deserialize(org.apache.kafka.clients.consumer.ConsumerRecord)> in (KafkaShuffleFetcher.java:108)
Method <org.apache.flink.streaming.runtime.tasks.SourceOperatorStreamTask.init()> calls method <org.apache.flink.streaming.api.operators.SourceOperator.getSourceReader()> in (SourceOperatorStreamTask.java:72)
Method <org.apache.flink.streaming.runtime.tasks.StreamTask.isMailboxLoopRunning()> calls method <org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.isMailboxLoopRunning()> in (StreamTask.java:801)
Method <org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxStep()> calls method <org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxStep()> in (StreamTask.java:796)
Method <org.apache.flink.streaming.runtime.tasks.mailbox.MailboxExecutorImpl.isIdle()> calls method <org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.isDefaultActionAvailable()> in (MailboxExecutorImpl.java:63)
Method <org.apache.flink.table.catalog.CatalogManager.getPermanentTable(org.apache.flink.table.catalog.ObjectIdentifier)> calls method <org.apache.flink.table.catalog.CatalogManager$TableLookupResult.permanent(org.apache.flink.table.catalog.Catalog, org.apache.flink.table.catalog.ResolvedCatalogBaseTable)> in (CatalogManager.java:428)
Method <org.apache.flink.table.catalog.CatalogManager.getTable(org.apache.flink.table.catalog.ObjectIdentifier)> calls method <org.apache.flink.table.catalog.CatalogManager$TableLookupResult.temporary(org.apache.flink.table.catalog.ResolvedCatalogBaseTable)> in (CatalogManager.java:394)
Method <org.apache.flink.table.catalog.hive.util.HiveTableUtil.instantiateHiveTable(org.apache.flink.table.catalog.ObjectPath, org.apache.flink.table.catalog.CatalogBaseTable, org.apache.hadoop.hive.conf.HiveConf)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.isHiveTable(java.util.Map)> in (HiveTableUtil.java:379)
Method <org.apache.flink.table.data.writer.BinaryArrayWriter.getSegments()> calls method <org.apache.flink.table.data.writer.AbstractBinaryWriter.getSegments()> in (BinaryArrayWriter.java:30)
Method <org.apache.flink.table.data.writer.BinaryRowWriter.getSegments()> calls method <org.apache.flink.table.data.writer.AbstractBinaryWriter.getSegments()> in (BinaryRowWriter.java:27)
Method <org.apache.flink.table.planner.delegation.hive.HiveParser.parse(java.lang.String)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.getHiveVersion()> in (HiveParser.java:202)
Method <org.apache.flink.table.planner.delegation.hive.parse.HiveParserDDLSemanticAnalyzer.getTable(org.apache.flink.table.catalog.ObjectPath)> calls method <org.apache.flink.table.catalog.hive.HiveCatalog.getHiveTable(org.apache.flink.table.catalog.ObjectPath)> in (HiveParserDDLSemanticAnalyzer.java:271)
Method <org.apache.flink.table.planner.plan.nodes.exec.processor.utils.InputOrderCalculator.dealWithPossiblyRelatedBoundaries()> calls method <org.apache.flink.table.planner.plan.nodes.exec.processor.utils.TopologyGraph.canReach(org.apache.flink.table.planner.plan.nodes.exec.ExecNode, org.apache.flink.table.planner.plan.nodes.exec.ExecNode)> in (InputOrderCalculator.java:97)